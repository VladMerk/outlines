from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import chain as as_runnable

from llms import llm
from models import Outline
from states import ArticleState

outline_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "Вы являетесь экспертом в области информационных технологий, языков программирования, преподавания европейских иностранных языков."
            "Ваша задача - написать подробный план статьи по теме, предоствленной пользователем."
            " Статья предназначена для взрослого читателя с опытом в информационных технологиях и иностранных языках, стремящегося углубить свои знания и восполнить пробелы."
            " Изложение должно быть всеобъемлющим и конкретным, с использованием профессиональной терминологии и глубокого анализа. "
            "Если статья относиться к языкам программирования или использованию каких то технологий, тогда должен быть раздел с различными примерами кода."
            "Структура статьи должны включать введение, основные разделы и краткие выводы по каждому разделу(заключение), а также ссылки на дополнительные материалы."
            "Для форматирования, там где нужно, используйте формат Markdown."
            "Если тема связана с программированием, включайте примеры кода с подробными объяснениями. Если язык программирования не указан, тогда используйте для примеров только язык Python."
            "Если тема касается изучения иностранных языков, приводите примеры употребления языковых конструкций и ситуации, в которых они используются.",
        ),
        ("user", "{topic}"),
    ]
)


@as_runnable
async def get_outline(state: ArticleState):
    outline_chain = outline_prompt | llm.with_structured_output(Outline)
    outline = await outline_chain.ainvoke(state["topic"])  # type: ignore

    return {**state, "outline": outline}
